{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb47195-e6f1-4c94-80f2-40f686a759e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "subdir = 'hand_down'                # specify which hand gesture directory to save the image sequences\n",
    "n_frames_save = 8                   # specify how many frames in one sequence you wish to save\n",
    "iteration_counter = n_frames_save + 1\n",
    "folder_counter = 1\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands:\n",
    "    while capture.isOpened():\n",
    "        ret, frame = capture.read()\n",
    "        image = cv2.flip(frame, 1)\n",
    "        detected_image = hands.process(image)\n",
    "\n",
    "        if detected_image.multi_hand_landmarks:\n",
    "            for hand_lms in detected_image.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, hand_lms,\n",
    "                                          mp_hands.HAND_CONNECTIONS,\n",
    "                                          landmark_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(\n",
    "                                              color=(255, 0, 255), thickness=4, circle_radius=2),\n",
    "                                          connection_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(\n",
    "                                              color=(20, 180, 90), thickness=2, circle_radius=2)\n",
    "                                          )\n",
    "\n",
    "        cv2.imshow('Webcam', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('r'):\n",
    "            seq_folder_path = os.path.join('data', subdir, f'sequence{folder_counter}')\n",
    "            os.mkdir(seq_folder_path)\n",
    "            folder_counter += 1\n",
    "            iteration_counter = 1\n",
    "\n",
    "        if iteration_counter < n_frames_save + 1:\n",
    "            cv2.imwrite(os.path.join(seq_folder_path, f'{subdir}_sequence{folder_counter}_frame{iteration_counter}.jpg'), image)\n",
    "            if iteration_counter == n_frames_save:\n",
    "                print(f'Images for sequence {folder_counter - 1} saved.')\n",
    "            iteration_counter += 1\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff1f3079-116d-4bff-94d9-ad139a58d2fe",
   "metadata": {},
   "source": [
    "# Conv2D w/ LSTM (LCRN)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import imgaug.augmenters as iaa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    all_data_dir = 'data'\n",
    "    image_height, image_width = 120, 160\n",
    "    sequence_length = 8\n",
    "    X, y = [], []\n",
    "\n",
    "    image_seq_augmenter = iaa.Sequential([\n",
    "        iaa.Fliplr(0),\n",
    "        iaa.Crop(percent=(0, 0.1)),\n",
    "        iaa.LinearContrast((0.75, 1.5)),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 1.0)),\n",
    "        iaa.Multiply((0.8, 1.2), per_channel=0.2)\n",
    "    ])\n",
    "\n",
    "    for idx, class_name in enumerate(os.listdir(all_data_dir)):\n",
    "        for image_seq_name in os.listdir(os.path.join(all_data_dir, class_name)):\n",
    "            image_seq = []\n",
    "            for frame_name in os.listdir(os.path.join(all_data_dir, class_name, image_seq_name)):\n",
    "                frame = cv2.imread(os.path.join(all_data_dir, class_name, image_seq_name, frame_name))\n",
    "                frame = cv2.resize(frame, (image_height, image_width))\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image_seq.append(frame)\n",
    "            image_seq_aug = image_seq_augmenter(images=image_seq)\n",
    "            X.extend([image_seq, image_seq_aug])\n",
    "            y.extend([idx for i in range(2)])\n",
    "\n",
    "    X = (np.array(X) / 255.0).astype('float32') # (n_samples, n_frames, height, width, channels)\n",
    "    y = np.array(y)                             # (n_samples)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=1)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(restore_best_weights=True,\n",
    "                                                      patience=10)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        TimeDistributed(Conv2D(16, 3, activation='relu', input_shape=(sequence_length, image_height, image_width, 3),\n",
    "                   padding='same')),\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "        TimeDistributed(MaxPooling2D()),\n",
    "        TimeDistributed(Dropout(0.3)),\n",
    "\n",
    "        TimeDistributed(Conv2D(32, 3, activation='relu', padding='same')),\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "        TimeDistributed(MaxPooling2D()),\n",
    "        TimeDistributed(Dropout(0.3)),\n",
    "\n",
    "        TimeDistributed(Conv2D(64, 3, activation='relu', padding='same')),\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "        TimeDistributed(MaxPooling2D()),\n",
    "        TimeDistributed(Dropout(0.3)),\n",
    "\n",
    "        TimeDistributed(Conv2D(64, 3, activation='relu', padding='same')),\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "        TimeDistributed(MaxPooling2D()),\n",
    "        TimeDistributed(Dropout(0.3)),\n",
    "\n",
    "        TimeDistributed(Flatten()),\n",
    "        LSTM(32),\n",
    "        Dense(4),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    model_train_hist = model.fit(\n",
    "        X_train, y_train,\n",
    "        shuffle=True,\n",
    "        batch_size=4,\n",
    "        epochs=70,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "\n",
    "    model_eval_loss, model_eval_acc = model.evaluate(X_test, y_test)\n",
    "    date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "    current_date_time_dt = dt.datetime.now()\n",
    "    current_date_time_str = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "\n",
    "    model_name = f'model__date_time_{current_date_time_str}__loss_{model_eval_loss}__acc_{model_eval_acc}__hand.h5'\n",
    "    model.save(model_name)\n",
    "\n",
    "    df_train_hist = pd.DataFrame(model_train_hist.history)\n",
    "    df_train_hist.loc[:, ['loss', 'val_loss']].plot()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c3445-b58e-4faf-9a80-d828119903d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
